#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä»“åº“è´§ç‰©æ£€æµ‹ Web App
åŸºäº V7 ç‰ˆæœ¬ + V6 åº“å­˜è®¡ç®—
"""

import streamlit as st
import cv2
from ultralytics import YOLO
import os
import numpy as np
import tempfile
import random

# ==================== V7 æ ¸å¿ƒæ£€æµ‹å‡½æ•° (å°è£…) ====================

def detect_warehouse_goods_v7(image_path, output_path, conf=0.01, iou=0.5):
    """
    V7 æ ¸å¿ƒæ£€æµ‹é€»è¾‘
    è¿”å›: {'final': æ£€æµ‹æ•°é‡, 'counts': åˆ†ç±»ç»Ÿè®¡}
    """
    MODEL_PATH = 'yolov8l-world.pt'

    CLASSES = [
        'textile bale',
        'woven sack',
        'pillow',
        'sandbag',
        'wrapped package',
        'stacked white sacks',
        'wall of bales'
    ]

    MIN_AREA_RATIO = 0.001
    SLICE_MODE = True
    SLICE_HEIGHT = 640
    SLICE_WIDTH = 640
    SLICE_OVERLAP = 0.2
    AGNOSTIC_NMS = True
    CONF_THRESHOLD = conf
    DEDUP_THRESHOLD = 0.5

    # æ£€æŸ¥æ¨¡å‹
    if not os.path.exists(MODEL_PATH):
        return None

    # åŠ è½½æ¨¡å‹
    model = YOLO(MODEL_PATH)
    model.set_classes(CLASSES)

    # è¯»å–å›¾ç‰‡
    original_img = cv2.imread(image_path)
    h, w = original_img.shape[:2]
    total_area = w * h
    min_area = total_area * MIN_AREA_RATIO

    # åˆ‡ç‰‡è®¡ç®—
    slice_h = SLICE_HEIGHT
    slice_w = SLICE_WIDTH
    overlap_h = int(slice_h * SLICE_OVERLAP)
    overlap_w = int(slice_w * SLICE_OVERLAP)

    slices = []
    y_start = 0
    while y_start < h:
        y_end = min(y_start + slice_h, h)
        x_start = 0
        while x_start < w:
            x_end = min(x_start + slice_w, w)

            x1 = max(0, x_start - overlap_w if x_start > 0 else 0)
            y1 = max(0, y_start - overlap_h if y_start > 0 else 0)
            x2 = min(w, x_end + overlap_w if x_end < w else w)
            y2 = min(h, y_end + overlap_h if y_end < h else h)

            slices.append((x1, y1, x2, y2, x_start, y_start))
            x_start += slice_w - overlap_w
        y_start += slice_h - overlap_h

    all_boxes_before_nms = []

    # åˆ‡ç‰‡æ£€æµ‹
    for i, (x1, y1, x2, y2, x_offset, y_offset) in enumerate(slices, 1):
        slice_img = original_img[y1:y2, x1:x2]

        with tempfile.NamedTemporaryFile(suffix='.jpg', delete=False) as tmp:
            temp_path = tmp.name

        cv2.imwrite(temp_path, slice_img)

        results = model.predict(
            source=temp_path,
            conf=CONF_THRESHOLD,
            iou=iou,
            agnostic_nms=AGNOSTIC_NMS,
            verbose=False
        )

        os.remove(temp_path)

        result = results[0]
        boxes = result.boxes

        for box in boxes:
            cls_id = int(box.cls[0])
            conf_score = float(box.conf[0])
            xyxy = box.xyxy[0].cpu().numpy()

            xyxy[0] += x1
            xyxy[1] += y1
            xyxy[2] += x1
            xyxy[3] += y1

            all_boxes_before_nms.append({
                'cls': cls_id,
                'conf': conf_score,
                'xyxy': xyxy,
                'area': (xyxy[2] - xyxy[0]) * (xyxy[3] - xyxy[1])
            })

    # å…¨å±€å»é‡
    all_boxes_before_nms.sort(key=lambda x: x['conf'], reverse=True)

    unique_boxes = []
    for box in all_boxes_before_nms:
        is_duplicate = False
        x1, y1, x2, y2 = box['xyxy']

        for existing in unique_boxes:
            ex1, ey1, ex2, ey2 = existing['xyxy']

            ix1 = max(x1, ex1)
            iy1 = max(y1, ey1)
            ix2 = min(x2, ex2)
            iy2 = min(y2, ey2)

            if ix1 < ix2 and iy1 < iy2:
                intersection = (ix2 - ix1) * (iy2 - iy1)
                area1 = (x2 - x1) * (y2 - y1)
                area2 = (ex2 - ex1) * (ey2 - ey1)
                iou_val = intersection / (area1 + area2 - intersection)

                if iou_val > DEDUP_THRESHOLD:
                    is_duplicate = True
                    break

        if not is_duplicate:
            unique_boxes.append(box)

    # å°ºå¯¸è¿‡æ»¤
    final_boxes = []
    for box in unique_boxes:
        if box['area'] >= min_area:
            final_boxes.append(box)

    # ç”Ÿæˆå¯è§†åŒ–ç»“æœ
    annotated_img = original_img.copy()
    colors = {}
    for cls_id in range(len(CLASSES)):
        colors[cls_id] = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))

    for box in final_boxes:
        x1, y1, x2, y2 = map(int, box['xyxy'])
        cls_id = box['cls']
        conf = box['conf']

        color = colors.get(cls_id, (255, 255, 255))
        cv2.rectangle(annotated_img, (x1, y1), (x2, y2), color, 2)

        label = f"{conf:.2f}"
        cv2.putText(annotated_img, label, (x1+2, y2-2),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

    cv2.imwrite(output_path, annotated_img)

    # ç»Ÿè®¡åˆ†ç±»
    class_counts = {}
    for box in final_boxes:
        cls_id = box['cls']
        class_name = CLASSES[cls_id]
        class_counts[class_name] = class_counts.get(class_name, 0) + 1

    return {
        'final': len(final_boxes),
        'counts': class_counts,
        'result_image': output_path
    }


# ==================== Streamlit Web App ====================

def main():
    st.set_page_config(
        page_title="ä»“åº“è´§ç‰©æ£€æµ‹ç³»ç»Ÿ",
        page_icon="ğŸ“¦",
        layout="wide"
    )

    st.title("ğŸ“¦ ä»“åº“è´§ç‰©æ£€æµ‹ä¸åº“å­˜è®¡ç®—ç³»ç»Ÿ")
    st.markdown("---")

    # ä¾§è¾¹æ  - è¯´æ˜
    with st.sidebar:
        st.header("ç³»ç»Ÿè¯´æ˜")
        st.markdown("""
        **åŸºäº YOLO-World V7 ç‰ˆæœ¬**

        åŠŸèƒ½ï¼š
        - âœ… é›¶æ ·æœ¬è´§ç‰©æ£€æµ‹
        - âœ… æ™ºèƒ½å»é‡
        - âœ… åº“å­˜è®¡ç®—

        æ£€æµ‹ç±»åˆ«ï¼š
        - textile bale
        - woven sack
        - pillow
        - sandbag
        - wrapped package
        - stacked white sacks
        - wall of bales
        """)

    # ä¸»ç•Œé¢
    col1, col2 = st.columns([1, 1])

    with col1:
        st.subheader("ğŸ“¤ 1. ä¸Šä¼ å›¾ç‰‡")
        uploaded_file = st.file_uploader(
            "è¯·é€‰æ‹©ä¸€å¼ ä»“åº“å›¾ç‰‡",
            type=['jpg', 'jpeg', 'png'],
            help="æ”¯æŒ JPG, JPEG, PNG æ ¼å¼"
        )

        if uploaded_file is not None:
            # ä¿å­˜ä¸Šä¼ çš„å›¾ç‰‡
            with tempfile.NamedTemporaryFile(suffix='.jpg', delete=False) as tmp_input:
                input_path = tmp_input.name
                tmp_input.write(uploaded_file.read())

            # è¾“å‡ºè·¯å¾„
            with tempfile.NamedTemporaryFile(suffix='.jpg', delete=False) as tmp_output:
                output_path = tmp_output.name

            st.success(f"âœ… å›¾ç‰‡å·²ä¸Šä¼ : {uploaded_file.name}")

            # æ£€æµ‹æŒ‰é’®
            if st.button("ğŸ” å¼€å§‹æ£€æµ‹", type="primary"):
                with st.spinner("æ­£åœ¨æ£€æµ‹ä¸­ï¼Œè¯·ç¨å€™..."):
                    result = detect_warehouse_goods_v7(input_path, output_path)

                if result:
                    # ä¿å­˜ç»“æœåˆ° session_state
                    st.session_state['detection_result'] = result
                    st.session_state['output_path'] = output_path
                    st.session_state['input_path'] = input_path
                    st.success(f"âœ… æ£€æµ‹å®Œæˆï¼å‘ç° {result['final']} ä¸ªåŒ…è£¹")
                else:
                    st.error("âŒ æ£€æµ‹å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨")

            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try:
                os.remove(input_path)
            except:
                pass

    with col2:
        st.subheader("ğŸ“Š 2. æ£€æµ‹ç»“æœ")

        if 'detection_result' in st.session_state:
            result = st.session_state['detection_result']
            output_path = st.session_state['output_path']

            # æ˜¾ç¤ºç»“æœå›¾ç‰‡
            st.image(output_path, caption="æ£€æµ‹ç»“æœ", use_column_width=True)

            # æ–‡å­—ç»Ÿè®¡
            st.markdown("---")
            st.markdown(f"### ğŸ“¦ è§†è§‰è¯†åˆ«åˆ° **{result['final']}** ä¸ªå¯è§åŒ…è£¹")

            # åˆ†ç±»è¯¦æƒ…
            with st.expander("æŸ¥çœ‹åˆ†ç±»è¯¦æƒ…"):
                for cls_name, count in result['counts'].items():
                    st.markdown(f"- **{cls_name}**: {count} ä¸ª")

            st.markdown("---")

            # V6 åº“å­˜è®¡ç®—é€»è¾‘
            st.subheader("ğŸ§® 3. åº“å­˜è®¡ç®—")

            depth = st.number_input(
                "è¯·è¾“å…¥å †å æ·±åº¦ (Deep)ï¼š",
                min_value=1,
                max_value=100,
                value=1,
                step=1,
                help="æ¯å±‚å †å çš„æ·±åº¦æ•°é‡"
            )

            total = result['final'] * depth

            st.markdown("---")
            st.markdown(f"""
            <div style="padding: 20px; background-color: #f0f2f6; border-radius: 10px; text-align: center;">
                <h3 style="margin: 0; color: #1f77b4;">å½“å‰åº“å­˜æ€»æ•°</h3>
                <p style="margin: 10px 0; font-size: 24px;">
                    <strong>{result['final']} Ã— {depth} = {total}</strong>
                </p>
            </div>
            """, unsafe_allow_html=True)

            st.markdown("---")

            # ä¸‹è½½ç»“æœ
            with open(output_path, "rb") as file:
                st.download_button(
                    label="ğŸ“¥ ä¸‹è½½æ£€æµ‹ç»“æœå›¾",
                    data=file,
                    file_name="detection_result.jpg",
                    mime="image/jpeg"
                )

        else:
            st.info("ğŸ‘ˆ è¯·å…ˆä¸Šä¼ å›¾ç‰‡å¹¶ç‚¹å‡»æ£€æµ‹æŒ‰é’®")

if __name__ == "__main__":
    main()

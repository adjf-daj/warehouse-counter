#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä»“åº“è´§ç‰©æ£€æµ‹ç³»ç»Ÿ V13 (é€šç”¨å¢å¼ºç‰ˆ)
æ ¸å¿ƒå‡çº§ï¼š
1. [GPTå»ºè®®] æ”¯æŒè‡ªå®šä¹‰ Prompt (ä¸å†å±€é™äºçººç»‡è¢‹ï¼Œæƒ³æ•°ä»€ä¹ˆå¡«ä»€ä¹ˆ)
2. [GPTå»ºè®®] æ”¹ç”¨ç»å¯¹åƒç´ è¿‡æ»¤ (é˜²æ­¢è¯¯åˆ è¿œå¤„å°åŒ…)
3. ä¿ç•™ V12 çš„ç¡¬ç›˜ç¼“å­˜ä¸å†…å­˜ä¼˜åŒ–
"""

import streamlit as st
import cv2
from ultralytics import YOLO
import os
import numpy as np
import tempfile
import random
from PIL import Image
import shutil
import pandas as pd
from datetime import datetime
import time
import gc

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="AI é€šç”¨ç›˜ç‚¹ç³»ç»Ÿ V13",
    page_icon="ğŸ­",
    layout="wide",
    initial_sidebar_state="expanded"
)

# å®šä¹‰ç¼“å­˜ç›®å½•
CACHE_DIR = "processed_cache"
if not os.path.exists(CACHE_DIR):
    os.makedirs(CACHE_DIR)

# ==================== åç«¯é€»è¾‘ ====================

@st.cache_resource(show_spinner=False)
def load_model():
    """åŠ è½½æ¨¡å‹ (YOLO-World)"""
    try:
        # V13ä¿®æ”¹: è¿™é‡ŒåªåŠ è½½æ¨¡å‹æƒé‡ï¼Œä¸ç»‘å®šå…·ä½“ç±»åˆ«ï¼Œç±»åˆ«åœ¨æ£€æµ‹æ—¶åŠ¨æ€è®¾å®š
        model = YOLO('yolov8l-world.pt') 
        return model
    except Exception as e:
        st.error(f"æ¨¡å‹åŠ è½½å´©æºƒ: {str(e)}")
        return None

def clear_cache():
    """æ¸…ç†ç¼“å­˜"""
    if os.path.exists(CACHE_DIR):
        try:
            shutil.rmtree(CACHE_DIR)
            os.makedirs(CACHE_DIR)
        except Exception:
            pass

def detect_and_save(image_path, conf, iou, model, original_filename, target_classes):
    """
    V13 æ£€æµ‹é€»è¾‘: æ¥æ”¶è‡ªå®šä¹‰ç±»åˆ«åˆ—è¡¨ + ç»å¯¹åƒç´ è¿‡æ»¤
    """
    # åŠ¨æ€è®¾ç½®å½“å‰è¦æ‰¾çš„ç›®æ ‡
    model.set_classes(target_classes)

    SLICE_HEIGHT, SLICE_WIDTH = 640, 640
    SLICE_OVERLAP = 0.2
    AGNOSTIC_NMS = True
    DEDUP_THRESHOLD = iou
    
    # [GPTå»ºè®®] ä½¿ç”¨ç»å¯¹åƒç´ é¢ç§¯è¿‡æ»¤ï¼Œè€Œä¸æ˜¯ç™¾åˆ†æ¯”
    # 300åƒç´ å¤§çº¦æ˜¯ 17x17 çš„å°æ–¹å—ï¼Œå°äºè¿™ä¸ªçš„è§†ä¸ºå™ªç‚¹
    MIN_PIXEL_AREA = 300 

    # è¯»å–å›¾ç‰‡
    original_img = cv2.imread(image_path)
    if original_img is None: return None
    h, w = original_img.shape[:2]

    # åˆ‡ç‰‡è®¡ç®—
    overlap_h, overlap_w = int(SLICE_HEIGHT * SLICE_OVERLAP), int(SLICE_WIDTH * SLICE_OVERLAP)
    slices = []
    y_start = 0
    while y_start < h:
        y_end = min(y_start + SLICE_HEIGHT, h)
        x_start = 0
        while x_start < w:
            x_end = min(x_start + SLICE_WIDTH, w)
            x1, y1 = max(0, x_start - overlap_w if x_start > 0 else 0), max(0, y_start - overlap_h if y_start > 0 else 0)
            x2, y2 = min(w, x_end + overlap_w if x_end < w else w), min(h, y_end + overlap_h if y_end < h else h)
            slices.append((x1, y1, x2, y2, x_start, y_start))
            x_start += SLICE_WIDTH - overlap_w
        y_start += SLICE_HEIGHT - overlap_h

    # åˆ‡ç‰‡æ£€æµ‹
    all_boxes = []
    temp_dir = tempfile.mkdtemp()
    
    try:
        for i, (x1, y1, x2, y2, _, _) in enumerate(slices):
            slice_img = original_img[y1:y2, x1:x2]
            temp_path = os.path.join(temp_dir, f"slice_{i}.jpg")
            cv2.imwrite(temp_path, slice_img)
            
            # æ¨ç†
            results = model.predict(source=temp_path, conf=conf, iou=iou, agnostic_nms=AGNOSTIC_NMS, verbose=False)
            del slice_img
            
            for box in results[0].boxes:
                xyxy = box.xyxy[0].cpu().numpy()
                xyxy[0] += x1; xyxy[1] += y1; xyxy[2] += x1; xyxy[3] += y1
                all_boxes.append({
                    'cls': int(box.cls[0]), 'conf': float(box.conf[0]),
                    'xyxy': xyxy, 'area': (xyxy[2]-xyxy[0])*(xyxy[3]-xyxy[1])
                })
    finally:
        shutil.rmtree(temp_dir)

    # NMS å»é‡
    all_boxes.sort(key=lambda x: x['conf'], reverse=True)
    unique_boxes = []
    for box in all_boxes:
        if not any(compute_iou(box['xyxy'], xb['xyxy']) > DEDUP_THRESHOLD for xb in unique_boxes):
            unique_boxes.append(box)

    # [GPTå»ºè®®] ç»å¯¹é¢ç§¯è¿‡æ»¤
    final_boxes = [b for b in unique_boxes if b['area'] >= MIN_PIXEL_AREA]

    # ç»˜å›¾
    annotated_img = original_img.copy()
    random.seed(42)
    # åŠ¨æ€ç”Ÿæˆé¢œè‰²
    colors = {i: (random.randint(50, 255), random.randint(50, 255), random.randint(50, 255)) for i in range(len(target_classes))}
    
    class_counts = {}
    for box in final_boxes:
        # æ­¤æ—¶ model.names å·²ç»æ ¹æ® set_classes æ›´æ–°
        cls_name = model.names[box['cls']]
        class_counts[cls_name] = class_counts.get(cls_name, 0) + 1
        x1, y1, x2, y2 = map(int, box['xyxy'])
        
        color = colors.get(box['cls'], (0, 255, 0))
        cv2.rectangle(annotated_img, (x1, y1), (x2, y2), color, 2)

    # ä¿å­˜ç¼“å­˜
    save_name = f"{int(time.time())}_{original_filename}"
    save_path = os.path.join(CACHE_DIR, save_name)
    cv2.imwrite(save_path, annotated_img)

    # å†…å­˜æ¸…ç†
    del original_img
    del annotated_img
    del all_boxes
    gc.collect()

    return {
        'count': len(final_boxes),
        'img_path': save_path,
        'counts_detail': class_counts
    }

def compute_iou(box1, box2):
    ix1, iy1 = max(box1[0], box2[0]), max(box1[1], box2[1])
    ix2, iy2 = min(box1[2], box2[2]), min(box1[3], box2[3])
    if ix1 >= ix2 or iy1 >= iy2: return 0.0
    inter = (ix2 - ix1) * (iy2 - iy1)
    return inter / ((box1[2]-box1[0])*(box1[3]-box1[1]) + (box2[2]-box2[0])*(box2[3]-box2[1]) - inter + 1e-6)

# ==================== å‰ç«¯ UI ====================

def main():
    if 'data_store' not in st.session_state: st.session_state['data_store'] = {}
    if 'user_edits' not in st.session_state: st.session_state['user_edits'] = {}

    with st.spinner("ğŸš€ AI å¼•æ“åŠ è½½ä¸­..."):
        model = load_model()
    if not model: st.stop()

    with st.sidebar:
        st.title("ğŸ­ æ™ºèƒ½ç›˜ç‚¹æ§åˆ¶å°")
        st.caption("V13: é€šç”¨å¢å¼ºç‰ˆ")
        st.markdown("---")
        
        st.subheader("1. è¯†åˆ«ç›®æ ‡è®¾ç½®")
        # [GPTå»ºè®®] å¼€æ”¾ Prompt æ¥å£
        default_prompts = "textile bale, woven sack, wrapped package, stacked white sacks, wall of bales"
        user_prompt = st.text_area(
            "è¾“å…¥ä½ æƒ³æ•°çš„ç‰©ä½“ (è‹±æ–‡é€—å·åˆ†éš”)", 
            value=default_prompts,
            height=100,
            help="YOLO-World æ˜¯é€šç”¨çš„ï¼Œä½ å¯ä»¥è¾“å…¥ box, tire, bottle, helmet ç­‰ä»»ä½•ç‰©ä½“"
        )
        # æ¸…æ´—ç”¨æˆ·è¾“å…¥
        TARGET_CLASSES = [x.strip() for x in user_prompt.split(',') if x.strip()]
        
        st.subheader("2. çµæ•åº¦å‚æ•°")
        # é»˜è®¤å€¼å¾®è°ƒ
        conf = st.slider("ç½®ä¿¡åº¦ (Conf)", 0.01, 0.5, 0.05, help="é»˜è®¤0.05ï¼Œè¶Šå°å‘ç°è¶Šå¤š")
        iou = st.slider("å»é‡é˜ˆå€¼ (IoU)", 0.05, 0.8, 0.35, help="é»˜è®¤0.35ï¼Œé˜²æ­¢è¿‡åº¦åˆå¹¶")
        
        st.markdown("---")
        
        uploaded_files = st.file_uploader(
            "3. ä¸Šä¼ å›¾ç‰‡ (å»ºè®®åˆ†æ‰¹å¤„ç†)", 
            type=['jpg', 'png'], 
            accept_multiple_files=True
        )

        st.markdown("---")
        start_btn = st.button("ğŸš€ å¼€å§‹æ£€æµ‹", type="primary", use_container_width=True)
        
        if start_btn:
            if not uploaded_files:
                st.warning("âš ï¸ è¯·å…ˆä¸Šä¼ å›¾ç‰‡ï¼")
            elif not TARGET_CLASSES:
                st.warning("âš ï¸ è¯·è‡³å°‘è¾“å…¥ä¸€ä¸ªè¯†åˆ«ç›®æ ‡ï¼")
            else:
                # æ¸…ç†
                st.session_state['data_store'] = {}
                st.session_state['user_edits'] = {}
                clear_cache()
                gc.collect()
                
                st.info(f"æ­£åœ¨å¯»æ‰¾: {TARGET_CLASSES}")
                progress_bar = st.progress(0)
                
                for idx, file_obj in enumerate(uploaded_files):
                    progress_bar.progress((idx) / len(uploaded_files), text=f"æ­£åœ¨åˆ†æ: {file_obj.name}...")
                    
                    with tempfile.NamedTemporaryFile(delete=False, suffix='.jpg') as tmp:
                        tmp.write(file_obj.read())
                        tmp_path = tmp.name
                    
                    try:
                        # ä¼ å…¥ç”¨æˆ·è‡ªå®šä¹‰çš„ CLASSES
                        result = detect_and_save(tmp_path, conf, iou, model, file_obj.name, TARGET_CLASSES)
                        if result:
                            st.session_state['data_store'][file_obj.name] = result
                            st.session_state['user_edits'][file_obj.name] = {'depth': 1, 'manual': 0}
                    except Exception as e:
                        st.error(f"å‡ºé”™: {e}")
                    
                    os.remove(tmp_path)
                    gc.collect()
                
                progress_bar.progress(1.0, text="âœ… å®Œæˆï¼")
                time.sleep(0.5)
                st.rerun()

    # --- ä¸»ç•Œé¢ ---
    st.title("ğŸ­ ä»“åº“ç›˜ç‚¹æ€»è§ˆ")

    if not st.session_state['data_store']:
        st.info(f"ğŸ‘ˆ å‡†å¤‡å°±ç»ªã€‚å½“å‰è¯†åˆ«ç›®æ ‡: {len(TARGET_CLASSES)} ç±»ã€‚è¯·ä¸Šä¼ å›¾ç‰‡å¹¶å¼€å§‹ã€‚")
        with st.expander("æŸ¥çœ‹å½“å‰è¯†åˆ«åˆ—è¡¨"):
            st.write(TARGET_CLASSES)
        st.stop()

    # Dashboard
    total_ai_count = sum([d['count'] for d in st.session_state['data_store'].values()])
    grand_total = 0
    for name, result in st.session_state['data_store'].items():
        edits = st.session_state['user_edits'].get(name, {'depth': 1, 'manual': 0})
        grand_total += (result['count'] + edits['manual']) * edits['depth']

    col1, col2, col3 = st.columns(3)
    col1.metric("ğŸ“¸ å›¾ç‰‡æ•°é‡", f"{len(st.session_state['data_store'])} å¼ ")
    col2.metric("ğŸ“¦ AI è®¡æ•°", f"{total_ai_count} ä¸ª")
    col3.metric("ğŸ’° åº“å­˜æ€»è®¡", f"{grand_total} ä¸ª")
    
    st.markdown("---")

    # åˆ†å›¾æ ¡å¯¹
    st.subheader("ğŸ” æ ¡å¯¹ä¸ä¿®æ­£")
    file_list = list(st.session_state['data_store'].keys())
    
    col_sel1, col_sel2 = st.columns([3, 1])
    with col_sel1:
        selected_file = st.selectbox("é€‰æ‹©å›¾ç‰‡:", file_list, label_visibility="collapsed")
    
    if selected_file:
        data = st.session_state['data_store'][selected_file]
        edits = st.session_state['user_edits'][selected_file]

        c1, c2 = st.columns([2, 1])
        with c1:
            if os.path.exists(data['img_path']):
                st.image(data['img_path'], caption=f"æ–‡ä»¶: {selected_file}", use_container_width=True)
            else:
                st.error("å›¾ç‰‡ç¼“å­˜å¤±æ•ˆï¼Œè¯·é‡æ–°æ£€æµ‹")

        with c2:
            st.markdown(f"### è®¡æ•°: **{data['count']}**")
            # æ˜¾ç¤ºåˆ†ç±»è¯¦æƒ…
            with st.expander("åˆ†ç±»è¯¦æƒ…"):
                for k, v in data['counts_detail'].items():
                    st.write(f"- {k}: {v}")
            
            st.markdown("---")
            new_depth = st.number_input("å †å æ·±åº¦", min_value=1, value=edits['depth'], key=f"d_{selected_file}")
            new_manual = st.number_input("äººå·¥è¡¥å·®", value=edits['manual'], step=1, key=f"m_{selected_file}")
            
            st.session_state['user_edits'][selected_file]['depth'] = new_depth
            st.session_state['user_edits'][selected_file]['manual'] = new_manual
            
            this_total = (data['count'] + new_manual) * new_depth
            st.success(f"å°è®¡: {this_total}")

    st.markdown("---")

    # å¯¼å‡º
    st.subheader("ğŸ“¥ å¯¼å‡ºæŠ¥è¡¨")
    report_data = []
    for name, result in st.session_state['data_store'].items():
        e = st.session_state['user_edits'][name]
        final = (result['count'] + e['manual']) * e['depth']
        report_data.append({
            "æ–‡ä»¶å": name,
            "æ£€æµ‹ç›®æ ‡": str(TARGET_CLASSES), # è®°å½•è¿™æ‰¹æŸ¥çš„æ˜¯ä»€ä¹ˆ
            "AIè¯†åˆ«æ•°": result['count'],
            "äººå·¥è¡¥å·®": e['manual'],
            "å †å æ·±åº¦": e['depth'],
            "è¯¥å›¾æ€»åº“å­˜": final,
            "æ—¶é—´": datetime.now().strftime("%H:%M:%S")
        })
    
    df = pd.DataFrame(report_data)
    if not df.empty:
        csv = df.to_csv(index=False).encode('utf-8-sig')
        st.download_button("ğŸ“Š ä¸‹è½½å®Œæ•´æŠ¥è¡¨", csv, f"Report_{datetime.now().strftime('%Y%m%d')}.csv", "text/csv")

if __name__ == "__main__":
    main()

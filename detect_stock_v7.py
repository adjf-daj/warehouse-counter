#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä»“åº“è´§ç‰©æ£€æµ‹å·¥å…· - V7ç‰ˆï¼ˆä¿®å¤èƒŒæ™¯æ£€æµ‹ï¼‰
ç›®æ ‡ï¼šæ£€æµ‹å‡ºå·¦å³ä¸¤ä¾§å¢™å£ä¸Šçš„å¯†é›†è´§ç‰©
"""

import cv2
from ultralytics import YOLO
import argparse
import os
import sys
import numpy as np


def detect_warehouse_goods_v7(image_path, output_path='result_v7.jpg',
                              conf=0.01, iou=0.5, show=False):
    """
    V7ç‰ˆ - ä¿®å¤èƒŒæ™¯æ£€æµ‹
    1. æä½å°ºå¯¸é˜ˆå€¼ (0.1%)
    2. é‡æ–°å¼€å¯åˆ‡ç‰‡
    3. å¼ºåŒ–èƒŒæ™¯æç¤ºè¯
    4. è¯¦ç»†è°ƒè¯•è¾“å‡º
    """

    # ==================== V7 é…ç½®åŒºåŸŸ ====================
    # è‡ªåŠ¨ä¸‹è½½/åŠ è½½æ¨¡å‹
    MODEL_PATH = 'yolov8l-world.pt'

    # V7: å¼ºåŒ–èƒŒæ™¯æç¤ºè¯ + è½¯è¯
    CLASSES = [
        'textile bale',        # å·¥ä¸šè¯
        'woven sack',          # å·¥ä¸šè¯
        'pillow',              # è½¯è¯
        'sandbag',             # è½¯è¯
        'wrapped package',     # å·¥ä¸šè¯
        'stacked white sacks', # æ–°å¢ï¼šèƒŒæ™¯ç™½å¢™
        'wall of bales'        # æ–°å¢ï¼šèƒŒæ™¯è´§å †
    ]

    # V7 å…³é”®å‚æ•°
    MIN_AREA_RATIO = 0.001     # 0.1% - è¶…ä½é˜ˆå€¼ï¼Œä¿ç•™å°åŒ… (å…³é”®ä¿®å¤!)
    SLICE_MODE = True          # é‡æ–°å¼€å¯åˆ‡ç‰‡ï¼(å…³é”®ä¿®å¤!)
    SLICE_HEIGHT = 640         # åˆ‡ç‰‡é«˜åº¦
    SLICE_WIDTH = 640          # åˆ‡ç‰‡å®½åº¦
    SLICE_OVERLAP = 0.2        # 20%é‡å 
    AGNOSTIC_NMS = True        # ä¿æŒV4çš„ä¼˜ç‚¹ï¼Œè·¨ç±»åˆ«å»é‡
    IOU_THRESHOLD = iou        # 0.5 - ä¸¥æ ¼å»é‡
    CONF_THRESHOLD = conf      # 0.01 - ä½é˜ˆå€¼
    DEDUP_THRESHOLD = 0.5      # åˆ‡ç‰‡åˆå¹¶æ—¶çš„å»é‡é˜ˆå€¼
    # =================================================

    print("=" * 70)
    print("  ä»“åº“è´§ç‰©æ£€æµ‹å·¥å…· V7 - èƒŒæ™¯æ£€æµ‹ä¿®å¤ç‰ˆ")
    print("=" * 70)
    print("  ç›®æ ‡: æ£€å‡ºå·¦å³å¢™å£çš„å¯†é›†è´§ç‰©")
    print("  é…ç½®: æä½é˜ˆå€¼(0.1%) + åˆ‡ç‰‡å¼€å¯ + å¼ºåŒ–èƒŒæ™¯è¯")
    print("=" * 70)

    # 1. æ£€æŸ¥æ–‡ä»¶
    print("\n[æ­¥éª¤1/7] æ£€æŸ¥æ–‡ä»¶...")
    if not os.path.exists(image_path):
        print(f"âŒ é”™è¯¯: å›¾ç‰‡æ–‡ä»¶ '{image_path}' ä¸å­˜åœ¨")
        return None

    print(f"âœ… è¾“å…¥: {image_path}")

    # 2. åŠ è½½æ¨¡å‹
    print(f"\n[æ­¥éª¤2/7] åŠ è½½ YOLO-World æ¨¡å‹...")
    try:
        # YOLOä¼šè‡ªåŠ¨ä¸‹è½½æ¨¡å‹ï¼Œæ— éœ€æ‰‹åŠ¨æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        model = YOLO(MODEL_PATH) 
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"âŒ åŠ è½½å¤±è´¥: {e}")
        return None

    # 3. è®¾ç½®ç±»åˆ«
    print(f"\n[æ­¥éª¤3/7] è®¾ç½®æ£€æµ‹ç±»åˆ« ({len(CLASSES)}ç§)...")
    print("   (èƒŒæ™¯å¼ºåŒ–: stacked white sacks, wall of bales)")
    # for i, cls in enumerate(CLASSES, 1):
    #     print(f"   {i}. {cls}")
    model.set_classes(CLASSES)
    print("âœ… ç±»åˆ«è®¾ç½®å®Œæˆ")

    # 4. è¯»å–å›¾ç‰‡ä¿¡æ¯
    print(f"\n[æ­¥éª¤4/7] å›¾ç‰‡åˆ†æ...")
    original_img = cv2.imread(image_path)
    if original_img is None:
        print("âŒ æ— æ³•è¯»å–å›¾ç‰‡ï¼Œè¯·æ£€æŸ¥è·¯å¾„æˆ–æ ¼å¼")
        return None
        
    h, w = original_img.shape[:2]
    total_area = w * h
    min_area = total_area * MIN_AREA_RATIO

    print(f"   å›¾ç‰‡å°ºå¯¸: {w}x{h}")
    print(f"   æ€»é¢ç§¯: {total_area:,} åƒç´ ")
    print(f"   æœ€å°è¿‡æ»¤é¢ç§¯: {min_area:.2f} åƒç´  ({MIN_AREA_RATIO*100}%)")
    print(f"   åˆ‡ç‰‡é…ç½®: {SLICE_HEIGHT}x{SLICE_WIDTH}, é‡å  {SLICE_OVERLAP*100}%")

    # 5. æ‰§è¡Œåˆ‡ç‰‡æ£€æµ‹
    print(f"\n[æ­¥éª¤5/7] æ‰§è¡Œåˆ‡ç‰‡æ£€æµ‹...")
    print("   (SAHI ç®—æ³• - åˆ†å—æ£€æµ‹ååˆå¹¶)")

    # è®¡ç®—åˆ‡ç‰‡ç½‘æ ¼
    slice_h = SLICE_HEIGHT
    slice_w = SLICE_WIDTH
    overlap_h = int(slice_h * SLICE_OVERLAP)
    overlap_w = int(slice_w * SLICE_OVERLAP)

    # åˆ‡ç‰‡åæ ‡è®¡ç®—
    slices = []
    y_start = 0
    while y_start < h:
        y_end = min(y_start + slice_h, h)
        x_start = 0
        while x_start < w:
            x_end = min(x_start + slice_w, w)

            # è®¡ç®—å¸¦é‡å çš„åˆ‡å‰²åŒºåŸŸ
            x1 = max(0, x_start - overlap_w if x_start > 0 else 0)
            y1 = max(0, y_start - overlap_h if y_start > 0 else 0)
            x2 = min(w, x_end + overlap_w if x_end < w else w)
            y2 = min(h, y_end + overlap_h if y_end < h else h)

            slices.append((x1, y1, x2, y2, x_start, y_start))
            x_start += slice_w - overlap_w
        y_start += slice_h - overlap_h

    print(f"   ç”Ÿæˆ {len(slices)} ä¸ªåˆ‡ç‰‡")

    all_boxes_before_nms = []
    all_boxes_after_nms = []
    total_raw_detections = 0

    # åˆ›å»ºä¸´æ—¶ç›®å½•
    import tempfile
    temp_dir = tempfile.mkdtemp()
    
    try:
        for i, (x1, y1, x2, y2, x_offset, y_offset) in enumerate(slices, 1):
            # è£å‰ªåˆ‡ç‰‡
            slice_img = original_img[y1:y2, x1:x2]

            # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
            temp_path = os.path.join(temp_dir, f'temp_v7_slice_{i}.jpg')
            cv2.imwrite(temp_path, slice_img)

            # æ£€æµ‹
            results = model.predict(
                source=temp_path,
                conf=CONF_THRESHOLD,
                iou=IOU_THRESHOLD,
                agnostic_nms=AGNOSTIC_NMS,
                verbose=False
            )

            result = results[0]
            boxes = result.boxes

            # ç»Ÿè®¡åŸå§‹æ£€æµ‹æ•°
            total_raw_detections += len(boxes)

            # è½¬æ¢åæ ‡å¹¶æ”¶é›†
            if len(boxes) > 0:
                for box in boxes:
                    cls_id = int(box.cls[0])
                    conf_score = float(box.conf[0])
                    xyxy = box.xyxy[0].cpu().numpy()

                    # åŠ ä¸Šåç§»é‡ (æ˜ å°„å›åŸå›¾åæ ‡)
                    xyxy[0] += x1
                    xyxy[1] += y1
                    xyxy[2] += x1
                    xyxy[3] += y1

                    all_boxes_before_nms.append({
                        'cls': cls_id,
                        'conf': conf_score,
                        'xyxy': xyxy,
                        'area': (xyxy[2] - xyxy[0]) * (xyxy[3] - xyxy[1])
                    })

            # è¿›åº¦æç¤º
            if i % 4 == 0 or i == len(slices):
                print(f"   å·²å¤„ç†åˆ‡ç‰‡ {i}/{len(slices)}...", end='\r')

    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        import shutil
        shutil.rmtree(temp_dir)

    print(f"\n\nâœ… åˆ‡ç‰‡æ£€æµ‹å®Œæˆ")
    print(f"   åŸå§‹æ£€æµ‹æ€»æ•°: {len(all_boxes_before_nms)} ä¸ª")

    # 6. å…¨å±€å»é‡
    print(f"\n[æ­¥éª¤6/7] å…¨å±€å»é‡...")

    if not all_boxes_before_nms:
        print("âŒ æœªæ£€æµ‹åˆ°ä»»ä½•ç‰©ä½“")
        return None

    # æŒ‰ç½®ä¿¡åº¦æ’åº
    all_boxes_before_nms.sort(key=lambda x: x['conf'], reverse=True)

    # åº”ç”¨agnostic NMS
    unique_boxes = []
    for box in all_boxes_before_nms:
        is_duplicate = False
        x1, y1, x2, y2 = box['xyxy']

        for existing in unique_boxes:
            ex1, ey1, ex2, ey2 = existing['xyxy']

            # è®¡ç®—IoU
            ix1 = max(x1, ex1)
            iy1 = max(y1, ey1)
            ix2 = min(x2, ex2)
            iy2 = min(y2, ey2)

            if ix1 < ix2 and iy1 < iy2:
                intersection = (ix2 - ix1) * (iy2 - iy1)
                area1 = (x2 - x1) * (y2 - y1)
                area2 = (ex2 - ex1) * (ey2 - ey1)
                iou = intersection / (area1 + area2 - intersection)

                if iou > DEDUP_THRESHOLD:
                    is_duplicate = True
                    break

        if not is_duplicate:
            unique_boxes.append(box)

    all_boxes_after_nms = unique_boxes
    print(f"   NMSåæ•°é‡: {len(all_boxes_after_nms)} ä¸ª")

    # 7. å°ºå¯¸è¿‡æ»¤ï¼ˆæä½é˜ˆå€¼ï¼‰
    print(f"\n[æ­¥éª¤7/7] å°ºå¯¸è¿‡æ»¤...")
    final_boxes = []
    filtered_count = 0

    for box in all_boxes_after_nms:
        if box['area'] >= min_area:
            final_boxes.append(box)
        else:
            filtered_count += 1

    print(f"   è¿‡æ»¤å‰: {len(all_boxes_after_nms)} ä¸ª")
    print(f"   è¿‡æ»¤å: {len(final_boxes)} ä¸ª")
    print(f"   è¿‡æ»¤æ‰: {filtered_count} ä¸ª (<{MIN_AREA_RATIO*100}% é¢ç§¯)")

    # æ‰“å°è°ƒè¯•ä¿¡æ¯
    print("\n" + "=" * 70)
    print("  ğŸ” è°ƒè¯•è¾“å‡º - æ£€æµ‹æµç¨‹è¿½è¸ª")
    print("=" * 70)
    print(f"  1. åŸå§‹åˆ‡ç‰‡æ£€æµ‹: {total_raw_detections} ä¸ªæ¡†")
    print(f"  2. å…¨å±€å»é‡(NMS): {len(all_boxes_after_nms)} ä¸ªæ¡†")
    print(f"  3. å°ºå¯¸è¿‡æ»¤å:   {len(final_boxes)} ä¸ªæ¡†")
    print(f"  4. è¿‡æ»¤æŸå¤±ç‡:    {((total_raw_detections - len(final_boxes)) / (total_raw_detections + 1e-6) * 100):.1f}%")
    print("=" * 70)

    # ç”Ÿæˆç»“æœ
    if len(final_boxes) > 0:
        print(f"\nğŸ“Š æœ€ç»ˆç»“æœç»Ÿè®¡:")
        print("=" * 50)

        # åˆ†ç±»ç»Ÿè®¡
        class_counts = {}
        total_calculated = 0

        for box in final_boxes:
            cls_id = box['cls']
            class_name = CLASSES[cls_id]
            class_counts[class_name] = class_counts.get(class_name, 0) + 1
            total_calculated += 1

        for cls_name, count in class_counts.items():
            if count > 0:
                print(f"  {cls_name}: {count} ä¸ª")

        print("=" * 50)
        print(f"  è§†è§‰æ£€æµ‹æ€»è®¡: {total_calculated} ä¸ªåŒ…è£¹")
        print("=" * 50)

        # ä¿å­˜å¯è§†åŒ–ç»“æœ
        print(f"\nğŸ’¾ ç”Ÿæˆå¯è§†åŒ–ç»“æœ...")
        annotated_img = original_img.copy()

        # ä¸åŒç±»åˆ«ç”¨ä¸åŒé¢œè‰²
        import random
        random.seed(42) # å›ºå®šé¢œè‰²
        colors = {}
        for cls_id in range(len(CLASSES)):
            colors[cls_id] = (random.randint(50, 255), random.randint(50, 255), random.randint(50, 255))

        for box in final_boxes:
            x1, y1, x2, y2 = map(int, box['xyxy'])
            cls_id = box['cls']
            conf = box['conf']
            class_name = CLASSES[cls_id]

            color = colors.get(cls_id, (0, 255, 0))
            # ç”»ç»†ä¸€ç‚¹çš„æ¡†ï¼Œé¿å…é®æŒ¡
            cv2.rectangle(annotated_img, (x1, y1), (x2, y2), color, 1)

            # æ ‡ç­¾ä¸è¦é®æŒ¡å¤ªå¤š
            # label = f"{conf:.2f}"
            # cv2.putText(annotated_img, label, (x1, y1-2),
            #             cv2.FONT_HERSHEY_SIMPLEX, 0.3, color, 1)

        cv2.imwrite(output_path, annotated_img)
        print(f"âœ… ç»“æœå›¾å·²ä¿å­˜: {output_path}")

        # æ‰“å°ç»“è®º
        print("\n" + "=" * 70)
        if total_calculated >= 50:
            print(f"âœ… æˆåŠŸï¼æ£€æµ‹åˆ° {total_calculated} ä¸ªåŒ…è£¹")
            print(f"   V7 åº”è¯¥å·²ç»çœ‹è§äº†èƒŒæ™¯å¢™ä¸Šçš„å¤§éƒ¨åˆ†è´§ç‰©ï¼")
        else:
            print(f"âš ï¸ æ£€æµ‹æ•°é‡: {total_calculated} ä¸ª")
            print(f"   å¦‚æœèƒŒæ™¯è¿˜æ˜¯ç©ºçš„ï¼Œè¯·æ£€æŸ¥å›¾ç‰‡å…‰çº¿æ˜¯å¦è¿‡æš—ã€‚")
        print("=" * 70)

        return {
            'raw': total_raw_detections,
            'nms': len(all_boxes_after_nms),
            'final': len(final_boxes),
            'counts': class_counts
        }

    else:
        print("\nâŒ æœªæ£€æµ‹åˆ°ä»»ä½•è´§ç‰©")
        return None


def main():
    parser = argparse.ArgumentParser(description='ä»“åº“è´§ç‰©æ£€æµ‹ V7 - èƒŒæ™¯ä¿®å¤ç‰ˆ')
    parser.add_argument('--image', type=str, default='test.jpg', help='è¾“å…¥å›¾ç‰‡è·¯å¾„')
    parser.add_argument('--output', type=str, default='result_v7.jpg', help='è¾“å‡ºå›¾ç‰‡è·¯å¾„')
    parser.add_argument('--conf', type=float, default=0.01, help='ç½®ä¿¡åº¦é˜ˆå€¼')
    parser.add_argument('--iou', type=float, default=0.5, help='IoU é˜ˆå€¼')
    parser.add_argument('--show', action='store_true', help='æ˜¾ç¤ºç»“æœ')

    args = parser.parse_args()

    detect_warehouse_goods_v7(
        image_path=args.image,
        output_path=args.output,
        conf=args.conf,
        iou=args.iou,
        show=args.show
    )


if __name__ == "__main__":
    main()
